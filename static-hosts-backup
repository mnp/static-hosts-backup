#!/usr/bin/perl
#
# static-hosts-backup : Make a backup list of hosts and IP's for sites
# found in your browser histories.  Suitable for appending to your OS
# hosts file.
#
# USAGE: Run with no arguments, save output to a just-in-case file.
#
# This quick hack can be useful if your DNS should fail, become
# censored, corrupted, etc. Obviously, major sites will have static
# IP's so only these will be valid longer term.
#
# BUG: Also obviously, major sites usually employ DNS round-robin load
# balancing, so only one of their IP's will be captured here (see
# above, quick hack). To do this right, we would use Net::DNS to
# capture all A records, and then load these into a local resolver
# like dnsmasq.
#
# Linux Notes
# -----------
# 1. This requires sqlite3 to be installed. If you don't have it, do
# this first:  sudo apt-get install sqlite3.
#
# 2. Searches Chrome and Firefox histories.
#
# Other Platforms
# ---------------
# TODO
#
#
# Copyright (C) 2014 Mitchell Perilstein
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

use warnings;
use strict;
use Socket;

my $linux_chrome  = $ENV{HOME} . '/.config/google-chrome/Default/History';
my $linux_firefox = $ENV{HOME} . '/.mozilla/firefox/profiles.ini';

my %hostnames;

# First scrape browser histories to develop list of URL's

if (-f $linux_chrome) {
  scrape($linux_chrome, 'select url from urls' );
}

if (-f $linux_firefox) {
  open INI, $linux_firefox or die $!;
  while (<INI>) {
    if (/Path=(.*)$/) {
      scrape("~/.mozilla/firefox/$1/places.sqlite", 'select url from moz_places');
    }
  }
  close INI;
}

die "No history entries found"
  unless %hostnames;


# List in hand, look up each using builtin resolver; dump in hosts format

for my $h (keys %hostnames) {
  my $packed_ip = gethostbyname($h);
  if (defined $packed_ip) {
    printf("%s\t%s\n", inet_ntoa($packed_ip), $h);
  }
}

exit 0;

sub scrape {
  my ($dbfile, $query) = @_;

  open SQL, "sqlite3 $dbfile '$query' |"
    or die "sqlite3: $!";

  while (<SQL>) {
    m{https?://(.*?)/} and $hostnames{$1} = 1;
  }

  close SQL;
}





